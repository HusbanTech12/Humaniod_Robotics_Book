{
  "permissions": {
    "allow": [
      "Bash(npx docusaurus start --verbose)",
      "Bash(npx docusaurus start)",
      "Bash(npm run build)",
      "Bash(timeout 30 npx docusaurus start)",
      "Bash(npm install)",
      "Bash(git fetch --all --prune)",
      "Bash(.specify/scripts/bash/create-new-feature.sh --json \"/sp.specify Module 2: The Digital Twin (Gazebo & Unity)\n\nTarget audience:\nStudents, researchers, and engineers with foundational knowledge in AI and robotics, looking to simulate humanoid robots in realistic virtual environments. Audience is expected to be familiar with ROS 2 basics and Python programming.\n\nFocus and theme:\nCreating high-fidelity digital twins of humanoid robots and their environments for testing, validation, and human-robot interaction. Emphasis on physics-accurate simulation, sensor emulation, and environment visualization.\n\nGoal:\nEnable learners to design, simulate, and validate humanoid robots in virtual environments using Gazebo and Unity, integrating physics, sensors, and realistic interactions.\n\nLearning objectives:\n\nMaster Gazebo physics simulation: gravity, collisions, and dynamic interactions.\n\nBuild and configure humanoid digital twins in Gazebo using URDF/SDF models.\n\nSimulate sensor data for LiDAR, depth cameras, IMUs, and force/torque sensors.\n\nCreate interactive Unity environments for visualization and human-robot interaction.\n\nIntegrate sensor data streams into ROS 2 topics for perception and control pipelines.\n\nValidate simulation accuracy and correspondence with expected physical behaviors.\n\nSuccess criteria:\n\nFully simulated humanoid robot in Gazebo, with correct joint dynamics and collision responses.\n\nSensors produce realistic and testable data streams compatible with ROS 2.\n\nUnity environment accurately visualizes humanoid actions and supports user interaction.\n\nSensor fusion pipelines integrate simulated perception data with ROS 2 nodes for robot decision-making.\n\nDocumentation and diagrams enable reproducibility by other developers.\n\nConstraints:\n\nUse Gazebo 11 or later and Unity 2021+ versions compatible with ROS 2.\n\nFocus on humanoid robots and human-centered interactions; avoid unrelated robotics platforms.\n\nExclude VR/AR hardware-specific implementations; focus on simulation software only.\n\nMinimum 30% of examples must include integrated sensor pipelines.\n\nNot building:\n\nDetailed game mechanics or unrelated Unity scripting.\n\nHardware deployment outside simulated environments.\n\nFull multi-robot swarm simulations (focus on single humanoid robot).\n\nTechnical details:\n\nResearch-concurrent approach: Study Gazebo physics, URDF/SDF modeling, and Unity integration while authoring content.\n\nInclude example ROS 2 integration code snippets and simulation launch files.\n\nEnsure high-quality diagrams, screenshots, and environment layouts.\n\nCitation style: APA; include Gazebo/Unity documentation and peer-reviewed robotics research.\n\nTimeline and word count:\n\nWord count: 4,500–6,000 words for this module.\n\nTimeline: Complete module content within 1–1.5 weeks concurrent with simulation setup.\" --number 1 --short-name \"digital-twin\")",
      "Bash(.specify/scripts/bash/setup-plan.sh --json)",
      "Bash(.specify/scripts/bash/check-prerequisites.sh --json --require-tasks --include-tasks)"
    ],
    "deny": [],
    "ask": []
  }
}
